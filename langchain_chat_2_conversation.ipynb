{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Chat Part 2 - Conversation\n",
    "\n",
    "From DeepLearning.ai's `LangChain Chat with Your Data` course.\n",
    "\n",
    "Tutorial: https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/7/chat\n",
    "\n",
    "Be sure to persist vector store to disk by running langchain_chat_1_persist_vectore_store notebook before running this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Vectore Store from Filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "persist_directory = 'chroma/'\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "retriever=vectordb.as_retriever()\n",
    "\n",
    "# ConversationRetrievalChain adds a new step on top of the RetrievalQA chain.\n",
    "# It takes the history and the new question, and condenses it into a standalone question to pass to the vector store to look up relevant documents.\n",
    "# It also uses this condensed standalone question to pass to the language model to get an answer along with the relevant chunks from the vector store.\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the users question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "of this class will not be very program ming intensive, although we will do some \n",
      "programming, mostly in either MATLAB or Octa ve. I'll say a bit more about that later.  \n",
      "I also assume familiarity with basic proba bility and statistics. So most undergraduate \n",
      "statistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \n",
      "assume all of you know what ra ndom variables are, that all of you know what expectation \n",
      "is, what a variance or a random variable is. And in case of some of you, it's been a while \n",
      "since you've seen some of this material. At some of the discussion sections, we'll actually \n",
      "go over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n",
      "I'll say a bit more about that later as well.  \n",
      "Lastly, I also assume familiarity with basi c linear algebra. And again, most undergraduate \n",
      "linear algebra courses are more than enough. So if you've taken courses like Math 51, \n",
      "103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \n",
      "gonna assume that all of you know what matrix es and vectors are, that you know how to \n",
      "multiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. If you know what an eigenvect or of a matrix is, that'd be even better. \n",
      "But if you don't quite know or if you're not qu ite sure, that's fine, too. We'll go over it in \n",
      "the review sections.\n",
      "\n",
      "Instructor (Andrew Ng) :Yeah, yeah. I mean, you’re asking about overfitting, whether \n",
      "this is a good model. I thi nk let’s – the thing’s you’re mentioning are maybe deeper \n",
      "questions about learning algorithms  that we’ll just come back to later, so don’t really \n",
      "want to get into that right now. Any more questions? Okay.  \n",
      "So this endows linear regression with a proba bilistic interpretati on. I’m actually going to \n",
      "use this probabil – use this, sort of, probabilist ic interpretation in order to derive our next \n",
      "learning algorithm, which will be our first classification algorithm. Okay? So you’ll recall \n",
      "that I said that regression problems are where the variable Y that you’re trying to predict \n",
      "is continuous values. Now I’m actually gonna ta lk about our first cl assification problem, \n",
      "where the value Y you’re trying to predict will be discreet value. You can take on only a \n",
      "small number of discrete values and in th is case I’ll talk about binding classification \n",
      "where Y takes on only two values, right? So you  come up with classi fication problems if \n",
      "you’re trying to do, say, a medical diagnosis and try to decide based on some features that \n",
      "the patient has a disease or does not have a di sease. Or if in the housing example, maybe \n",
      "you’re trying to decide will this house sell in the next six months or not and the answer is \n",
      "either yes or no. It’ll either be  sold in the next six months or it won’t be. Other standing\n",
      "\n",
      "statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \n",
      "refresher for those of you that want one.  \n",
      "Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \n",
      "material that I'm teaching in the main lectur es. So machine learning is a huge field, and \n",
      "there are a few extensions that we really want  to teach but didn't have time in the main \n",
      "lectures for.\n",
      "\n",
      "come back to this again. Any questions a bout this? Actually, let me clean up another \n",
      "couple of boards and then I’ll see what questions you have.  \n",
      "Okay. Any questions? Yeah?  \n",
      "Student: You are, I think here you try to measure the likelihood of your nice of theta by a \n",
      "fraction of error, but I think it’s that you measure because it depends on the family of \n",
      "theta too, for example. If you have a lot of  parameters [inaudible] or fitting in?\n",
      "Human: Is probability a class topic?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Yes, probability is a topic that will be covered in the class. The instructor mentions assuming familiarity with basic probability and statistics, and also mentions using a probabilistic interpretation to derive a learning algorithm.\n"
     ]
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa({\"question\": question})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Is probability a class topic?\n",
      "Assistant: Yes, probability is a topic that will be covered in the class. The instructor mentions assuming familiarity with basic probability and statistics, and also mentions using a probabilistic interpretation to derive a learning algorithm.\n",
      "Follow Up Input: why are those prerequesites needed?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the users question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \n",
      "without even knowing it.  \n",
      "And of course, learning algorithms are also  doing things like giving us a growing \n",
      "understanding of the human genome. So if so meday we ever find a cure for cancer, I bet \n",
      "learning algorithms will have had a large role in that. That's sort of the thing that Tom \n",
      "works on, yes?  \n",
      "So in teaching this class, I sort of have thre e goals. One of them is just to I hope convey \n",
      "some of my own excitement a bout machine learning to you.  \n",
      "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\n",
      "the-art machine learning algorithms to whatev er problems you're interested in. And if you \n",
      "ever need to build a system for reading zi p codes, you'll know how to do that by the end \n",
      "of this class.  \n",
      "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \n",
      "doing research in machine learning, but by the c onclusion of this class,  I hope that all of \n",
      "you will actually be well qualified to star t doing research in machine learning, okay?  \n",
      "So let's say a few words about logistics. The prerequisites of this class are written on one \n",
      "of the handouts, are as follows: In this class, I'm going to assume that all of you have sort \n",
      "of basic knowledge of computer science and kn owledge of the basic computer skills and \n",
      "principles. So I assume all of you know what big?O notation, that all of you know about\n",
      "\n",
      "algorithm for reading zip codes. When can  you prove a theorem guaranteeing that a \n",
      "learning algorithm will be at least 99.9 per cent accurate on reading zip codes? This is \n",
      "actually somewhat surprising. We actually prove theorems showing when you can expect \n",
      "that to hold.  \n",
      "We'll also sort of delve into learning theo ry to try to understand what algorithms can \n",
      "approximate different functions well and also  try to understand things like how much \n",
      "training data do you need? So how many exampl es of houses do I need in order for your \n",
      "learning algorithm to recognize the pattern be tween the square footage of a house and its \n",
      "housing price? And this will help  us answer questions like if you're trying to design a \n",
      "learning algorithm, should you be spending more time collecting more data or is it a case \n",
      "that you already have enough data; it would be  a waste of time to try to collect more. \n",
      "Okay?  \n",
      "So I think learning algorithms are a very powerful tool that  as I walk around sort of \n",
      "industry in Silicon Valley or as I work with  various businesses in CS and outside CS, I \n",
      "find that there's often a huge differen ce between how well so meone who really \n",
      "understands this stuff can appl y a learning algorithm versus so meone who sort of gets it \n",
      "but sort of doesn't.  \n",
      "The analogy I like to think of  is imagine you were going to a carpentry school instead of \n",
      "a machine learning class, right? If you go to a carpentry school, they can give you the\n",
      "\n",
      "So in supervised learning, this is what we 're going to do. We're given a training set, and \n",
      "we're going to feed our training set, compri sing our M training example, so 47 training \n",
      "examples, into a learning algorithm. Okay, and our algorithm then has output function \n",
      "that is by tradition, and for hist orical reasons, is usually de noted lower case alphabet H, \n",
      "and is called a hypothesis. Don't worry too mu ch about whether the term hypothesis has a \n",
      "deep meaning. It's more a term that's used for historical reasons.  \n",
      "And the hypothesis's job is to take this i nput. There's some new [inaudible]. What the \n",
      "hypothesis does is it takes this  input, a new living area in s quare feet saying and output \n",
      "estimates the price of this house. So the hypothesis H maps from inputs X to outputs Y. \n",
      "So in order to design a learning algorithm, the first thing we have to decide is how we \n",
      "want to represent the hypothesis, right.  \n",
      "And just for this purposes of th is lecture, for the purposes of  our first learning algorithm, \n",
      "I'm going to use a linear representation for the hypothesis. So I'm going to represent my \n",
      "hypothesis as H of X equals theta zero, plus th eta 1X, where X here is  an input feature, \n",
      "and so that's the size of the house we're considering.  \n",
      "And more generally, come back to this, mo re generally for many regression problems we \n",
      "may have more than one input feature. So for example, if instead of  just knowing the size\n",
      "\n",
      "Instructor (Andrew Ng) :Yeah, yeah. I mean, you’re asking about overfitting, whether \n",
      "this is a good model. I thi nk let’s – the thing’s you’re mentioning are maybe deeper \n",
      "questions about learning algorithms  that we’ll just come back to later, so don’t really \n",
      "want to get into that right now. Any more questions? Okay.  \n",
      "So this endows linear regression with a proba bilistic interpretati on. I’m actually going to \n",
      "use this probabil – use this, sort of, probabilist ic interpretation in order to derive our next \n",
      "learning algorithm, which will be our first classification algorithm. Okay? So you’ll recall \n",
      "that I said that regression problems are where the variable Y that you’re trying to predict \n",
      "is continuous values. Now I’m actually gonna ta lk about our first cl assification problem, \n",
      "where the value Y you’re trying to predict will be discreet value. You can take on only a \n",
      "small number of discrete values and in th is case I’ll talk about binding classification \n",
      "where Y takes on only two values, right? So you  come up with classi fication problems if \n",
      "you’re trying to do, say, a medical diagnosis and try to decide based on some features that \n",
      "the patient has a disease or does not have a di sease. Or if in the housing example, maybe \n",
      "you’re trying to decide will this house sell in the next six months or not and the answer is \n",
      "either yes or no. It’ll either be  sold in the next six months or it won’t be. Other standing\n",
      "Human: Why is it necessary to assume familiarity with basic probability and statistics and use a probabilistic interpretation to derive a learning algorithm?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "It is necessary to assume familiarity with basic probability and statistics because learning algorithms often involve making probabilistic assumptions about the data. These assumptions help in modeling the relationship between the input features and the output values. By using a probabilistic interpretation, we can derive learning algorithms that can make predictions and classify data based on these assumptions. Probability and statistics provide the mathematical foundation for understanding and analyzing the performance of these algorithms.\n"
     ]
    }
   ],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
