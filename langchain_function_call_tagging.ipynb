{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Function Call Tagging\n",
    "\n",
    "From: https://learn.deeplearning.ai/functions-tools-agents-langchain/lesson/5/tagging-and-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Pydantic (a validation library) to Define Functions\n",
    "\n",
    "Pydantic is just a validation library. But LangChain uses it (along with its `convert_pydantic_to_openai_function` function) to make it easier to define function definitions that adheres to OpenAI function calling format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Tagging\",\n",
      "    \"description\": \"Tag the piece of text with particular info.\",\n",
      "    \"parameters\": {\n",
      "        \"title\": \"Tagging\",\n",
      "        \"description\": \"Tag the piece of text with particular info.\",\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"sentiment\": {\n",
      "                \"title\": \"Sentiment\",\n",
      "                \"description\": \"sentiment of text, should be `pos`, `neg`, or `neutral`\",\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"language\": {\n",
      "                \"title\": \"Language\",\n",
      "                \"description\": \"language of text (should be ISO 639-1 code)\",\n",
      "                \"type\": \"string\"\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"sentiment\",\n",
      "            \"language\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n",
    "    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")\n",
    "\n",
    "tagging_function = convert_pydantic_to_openai_function(Tagging)\n",
    "\n",
    "print(json.dumps(tagging_function, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "tagging_functions = [tagging_function]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"Tagging\"} # Instruct OpenAI to always respond with function call using Tagging\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"sentiment\": \"pos\",\\n  \"language\": \"en\"\\n}', 'name': 'Tagging'}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"I love langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"sentiment\": \"neg\",\\n  \"language\": \"it\"\\n}', 'name': 'Tagging'}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Out Relevant Information\n",
    "\n",
    "That `additional_kwargs` in the above output is ugly. We know the response will always be function_call b/c we forced it with `function_call={\"name\": \"Tagging\"}` and we know the arguments will always be JSON, so let's use `JsonOutputFunctionsParser` to just give us the final output in dict format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'neg', 'language': 'it'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()\n",
    "\n",
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
